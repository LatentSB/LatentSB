import argparse
import math
import os
import random
from pathlib import Path

import torch
from munch import munchify
from PIL import Image
from torchvision import transforms
from torchvision.utils import save_image
from tqdm import tqdm

from solver.latent_diffusion import get_solver


def set_seed(seed: int):
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)


def img_loader(root: Path):
    tf = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor()
    ])
    files = list(sorted(root.glob('*.png'))) + list(sorted(root.glob('*.jpg')))
    for f in files:
        yield tf(Image.open(f).convert('RGB')).unsqueeze(0)


def load_embedding(model, embedding_ckpt: Path):
    if embedding_ckpt is None:
        return None
    embedding = torch.load(embedding_ckpt)
    model.text_encoder.text_model.embeddings.token_embedding = embedding
    model.text_encoder.requires_grad_(False)
    return model.text_encoder

@torch.no_grad()
def sample(model, prompt, NFE, scale=7.5, zshape=(1, 4, 64, 64), init_x=None, **kwargs):
    tenc = kwargs.get('tenc_1')
    if tenc is not None:
        model.text_encoder = tenc

    uc, c = model.get_text_embed("", prompt)

    skip = 1000 // NFE 
    times = model.scheduler.timesteps

    if init_x is None:
        xt = torch.randn(zshape).to(model.device)
    else:
        xt = init_x  # generated by inversion

    pbar = tqdm(times, desc='Sampling')
    for idx, t in enumerate(pbar):
        at = model.alpha(t.long())
        pred_uc, pred_c = model.predict_noise(xt, t, uc, c)
        pred = pred_uc + scale * (pred_c - pred_uc)
        x0t = (xt - (1-at).sqrt()*pred)/at.sqrt()
        if idx < NFE - 1:
            atn = model.alpha((t-skip).long())
            xt = atn.sqrt()*x0t + (1-atn).sqrt()*pred
        else:
            xt = x0t

    img = model.decode(xt)
    img = (img+1.0)/2
    return img

@torch.no_grad()
def inversion(model, img, prompt, NFE, scale=0.0, **kwargs):
    """
    DDIM Inversion. As a default, we only use null-text for the inversion.
    In other words, we use w=0.0. 
    """
    uc, c = model.get_text_embed("", prompt)
    x0 = model.encode(img.cuda()*2-1)

    skip = 1000 // NFE
    times = reversed(model.scheduler.timesteps)
    xt = x0.clone()
    pbar = tqdm(times, desc='Inversion')
    for idx, t in enumerate(pbar):
        at = model.alpha(t.long())
        atn = model.alpha((t-skip).long())
        pred_uc, pred_c = model.predict_noise(xt, t, uc, c)
        pred = pred_uc + scale * (pred_c - pred_uc)

        x0t = (xt - (1-atn).sqrt()*pred)/atn.sqrt()
        xt = at.sqrt()*x0t + (1-at).sqrt()*pred
    return xt

@torch.no_grad()
def sb_sample(model, img, prompts, NFE, tau, t0, scale=7.5, **kwargs):
    """
    Proposed LatentSB ODE solver. 
    """

    def sb_to_vp(t, sigma):
        '''SNR matching'''
        a_s = 1/(1+sigma**2*t*(1-t))
        s = model.alpha_to_t(alpha_s=a_s)
        return s

    tenc_0 = kwargs.get('tenc_0')
    tenc_1 = kwargs.get('tenc_1')

    if tenc_0 is not None:
        model.text_encoder = tenc_0
    _, c0 = model.get_text_embed("", f"ugly, blurry, black, low res, unrealistic, {prompts[0]}")

    if tenc_1 is not None:
        model.text_encoder = tenc_1
    _, c1 = model.get_text_embed("ugly, blurry, black, low res, unrealistic", prompts[1])

    x0 = model.encode(img.cuda()*2-1)
    noise = torch.randn_like(x0).to(model.device)

    # initialize
    xt = (1-t0) * x0 + tau*math.sqrt(t0) * math.sqrt(1-t0) * noise
    
    sb_time = torch.linspace(t0, 1, NFE+1).to(model.device)
    pbar = tqdm(sb_time[:-1], desc='ODE')
    for idx, t in enumerate(pbar):
        if idx < NFE - 1:
            dt = sb_time[idx+1] - sb_time[idx]
        else:
            dt = sb_time[idx] - sb_time[idx-1]

        # SNR matching
        s = sb_to_vp(1-t, tau)
        a_s = model.alpha(round(s.item()))
        ys = xt * a_s.sqrt()

        eps_0, eps_1 = model.predict_noise(ys, s.round().long().squeeze(), c0, c1)

        # Source and target predictors
        x0t_0 = (ys - (1-a_s).sqrt() * eps_0)/a_s.sqrt()
        x0t_1 = (ys - (1-a_s).sqrt() * eps_1)/a_s.sqrt()

        # Time dependent noise
        eps = eps_1 if t > 0.5 else eps_0
        d1 = tau * (1-2*t)/(2*t.sqrt()*(1-t).sqrt()) * eps
        # CFG scale
        d2 = (x0t_1 - x0t_0) * scale
        # Euler update
        xt = xt + (d1 + d2) * dt

    # last denoising step
    s = sb_to_vp(1-t, tau)
    a_s = model.alpha(round(s.item()))
    a_sn = model.alpha(20)
    ys = xt * a_s.sqrt()
    _, eps_1 = model.predict_noise(ys, s.round().long().squeeze(), None, c1)
    x0t = (ys - (1-a_s).sqrt() * eps_1)/a_s.sqrt()
    xt = a_sn.sqrt() * x0t + (1-a_sn).sqrt() * eps_1

    img = model.decode(xt)
    img = (img+1.0)/2
    return img

@torch.no_grad()
def sdedit(model, img, prompts, NFE, tau, t0, scale=7.5, **kwargs):
    def sb_to_vp(t, sigma):
        a_s = 1/(1+sigma**2*t*(1-t))
        s = model.alpha_to_t(alpha_s=a_s)
        return s

    tenc_0 = kwargs.get('tenc_0')
    tenc_1 = kwargs.get('tenc_1')

    if tenc_0 is not None:
        model.text_encoder = tenc_0
    _, uc = model.get_text_embed("", f"ugly, blurry, black, low res, unrealistic, {prompts[0]}")
    if tenc_1 is not None:
        model.text_encoder = tenc_1
    _, c = model.get_text_embed("ugly, blurry, black, low res, unrealistic", prompts[1])

    # Make the same initial SNR with proposed method.
    s = sb_to_vp(t0, tau)
    a_s = model.alpha(round(s.item()))
    x0 = model.encode(img.cuda()*2-1)
    xt = a_s.sqrt() * x0 + (1-a_s).sqrt() * torch.randn_like(x0)


    times = torch.linspace(round(s.item())-1, 0, NFE).to(model.device).long() + 1
    skip = round(s.item()) // (NFE-1)

    pbar = tqdm(times, desc='SDEdit')
    for idx, t in enumerate(pbar):
        at = model.alpha(t.long())
        pred_uc, pred_c = model.predict_noise(xt, t, uc, c)
        pred = pred_uc + scale * (pred_c - pred_uc)
        x0t = (xt - (1-at).sqrt()*pred)/at.sqrt()
        if idx < NFE - 1:
            atn = model.alpha((t-skip).long())
            xt = atn.sqrt()*x0t + (1-atn).sqrt()*pred
        else:
            xt = x0t  # last step -> no renoising

    img = model.decode(xt)
    img = (img+1.0)/2
    return img

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--embedding_ckpt_0', type=Path, help='Source text embedding')
    parser.add_argument('--embedding_ckpt_1', type=Path, help="Target text embedding")
    parser.add_argument('--prompt_0', type=str, default='a photo of !', help="Source prompt")
    parser.add_argument('--prompt_1', type=str, default='a photo of *', help="Target prompt")
    parser.add_argument('--root', type=Path, default=Path('example'))
    parser.add_argument('--workdir', type=Path, default=Path('workdir/example/dog2wild'))
    parser.add_argument('--method', type=str, default='lsb', choices=['lsb', 'dual', 'sdedit', 'sample'])
    parser.add_argument('--tau', type=float, default=2.3)
    parser.add_argument('--t0', type=float, default=0.2)
    parser.add_argument('--scale', type=float, default=11.0)
    parser.add_argument('--NFE', type=int, default=8)
    parser.add_argument('--seed', type=int, default=0)
    args = parser.parse_args()

    set_seed(args.seed)
    args.workdir.joinpath('input').mkdir(exist_ok=True, parents=True)
    args.workdir.joinpath('edited').mkdir(exist_ok=True, parents=True)
    
    if args.method == 'dual':
        config = munchify({'num_sampling': args.NFE//2})
    elif args.method == 'lsb':
        config = munchify({'num_sampling': args.NFE-1})
    else:
        config = munchify({'num_sampling': args.NFE})

    # load Stable Diffusion and optimized text embedding
    model = get_solver(name='ddim', solver_config=config, device='cuda', pipe_dtype=torch.float32)
    tenc_0 = load_embedding(model, args.embedding_ckpt_0)
    tenc_1 = load_embedding(model, args.embedding_ckpt_1)

    prompts = [args.prompt_0, args.prompt_1]

    for i, img in enumerate(img_loader(args.root)):
        if args.method == "dual":
            xt = inversion(model, img, args.prompt_0, NFE=args.NFE//2, scale=0.0)
            out = sample(model, args.prompt_1, NFE=args.NFE//2, scale=args.scale, init_x=xt, tenc_1=tenc_1)
        elif args.method == "lsb":
            out = sb_sample(model, img, prompts, tau=args.tau, t0=args.t0, NFE=args.NFE-1, scale=args.scale, tenc_0=tenc_0, tenc_1=tenc_1)
        elif args.method == "sdedit":
            out = sdedit(model, img, prompts, tau=args.tau, t0=args.t0, NFE=args.NFE, scale=args.scale, tenc_0=tenc_0, tenc_1=tenc_1)
        elif args.method == "sample":
            out = sample(model, args.prompt_1, NFE=args.NFE, scale=args.scale, init_x=None, tenc_1=tenc_1)
        else:
            raise NameError(f"Unknown method: {args.method}")

        save_image(img, args.workdir.joinpath(f'input/img_{i}.png'))
        save_image(out, args.workdir.joinpath(f'edited/img_{i}.png'))